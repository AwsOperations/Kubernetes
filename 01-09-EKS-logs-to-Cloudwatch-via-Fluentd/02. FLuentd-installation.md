
# Fluentd with cloudwatch installation in kubernetes EKS.
```
Pre-requisites: Install ruby and gems inside your machine first because fluentd will look for rubygems and plugins.

$ sudo apt install rubygems  ----> for ubuntu servers
$ sudo yum install rubygems  ----> for redhat and amazon machines

Then goto ruby gems website download the .tar file and extract and install

https://rubygems.org/pages/download

https://rubygems.org/rubygems/rubygems-3.4.15.tgz

use tar command to unpack and get inside the directory

Install with: ruby setup.rb
```
-----------------------------------------------------------------------------------------------------------------------------------
**(Fluentd, EKS cluster, Cloudwatch)**

1. We need three files to make fluentd run inside EKS worker nodes
2. Please take a look at the files inside fluentd-configmap.yaml and fluentd-daemonset.yaml 
   where we need to give your cloudwatch credentials or enable role policy.
3. Install kubectl and update your eks config file to kubectl. using below command

https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html

$ aws eks update-kubeconfig --region us-east-1 --name eksdemo1

# Please clone the files into your repo

1. Fluentd-daemonset.yaml 	------> daemonset file to run on each worker node
2. FLuentd-configmap		------> configmap file to get attached to daemonset
3. Fluentd-rbac			------> Rbac roles file to give permissions to fluentd to access the pods

## Step 01: First We need to create EKS cluster
```
eksctl create cluster --name=eksdemo1 \
                      --region=us-east-1 \
                      --zones=us-east-1a,us-east-1b \
                      --version="1.27" \
                      --without-nodegroup 

## Step 02: we need to create eks nodegroup:

eksctl create nodegroup --cluster=eksdemo1 \
                        --region=us-east-1 \
                        --name=eksdemo1-ng-private1 \
                        --node-type=t3.medium \
                        --nodes-min=2 \
                        --nodes-max=4 \
                        --node-volume-size=20 \
                        --ssh-access \
                        --ssh-public-key=terraform-key \
                        --managed \
                        --asg-access \
                        --external-dns-access \
                        --full-ecr-access \
                        --appmesh-access \
                        --alb-ingress-access \
                        --node-private-networking    
```
## Step 03: we need to create iam-oidc-provider:
```
eksctl utils associate-iam-oidc-provider \
    --region us-east-1 \
    --cluster eksdemo1 \
    --approve
```
## Step-04: we need to create service account and attach cloudwatch policy:
```
eksctl create iamserviceaccount \
  --cluster=eksdemo1 \
  --namespace=kube-system \
  --name=fluentd \
  --attach-policy-arn=arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy \
  --override-existing-serviceaccounts \
  --approve
```
## Step 05: We have 3 sections in our fluentd-configmap.yaml :
```
1. From where we need to collect the logs source is /var/log/containers/*.log
2. Apply filters (filter kubernetes.**)
3. we need to configure a role or we can give credentials inside fluentd-config.yaml like below
or enable the role.

1. Below is 1st option.

<match **>
       @type cloudwatch_logs
       region us-east-1
       log_group_name k8s-nest
       log_stream_name fluentd
       auto_create_stream true
       auto_create_group true
       aws_key_id <Your aws access key>
       aws_sec_key <Your aws secret key>
       <buffer>
         flush_interval 5
         chunk_limit_size 2m
         queued_chunks_limit_size 32
         retry_forever true
       </buffer>
    </match>

2. Below is 2nd Option

Create a Role by using a json template like below:

{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "CloudWatchLogsAccess",
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": [
        "arn:aws:logs:<your-aws-region>:<your-aws-account-id>:log-group:<your-log-group-name>:*"
      ]
    }
  ]
}

3. After creating the above role policy attach this to EKS Cluster role which will be present in
   Cluster IAM role ARN in overview section of EKS cluster.

4. Create a log group in cloudwatch log group called eks-logs.
```
## Step 06: Now get inside the folders of Fluentd and start applying it.
```
$ cd 01-09-EKS logs to Cloudwatch via Fluentd

$ kubectl apply -f fluentd-configmap.yaml

$ kubectl apply -f fluentd-rbac.yaml 

$ kubectl apply -f fluentd-daemonset.yaml

$ kubectl get pods -n kube-system   			--------> checking the pods which is created under fluentd namespace
```
## Step 04: Let's deploy our example app that writes logs to stdout so that fluentd will collect logs and ship it to cloudwatch.
```
$ kubectl create deployment hello-node --image=registry.k8s.io/e2e-test-images/agnhost:2.39 -- /agnhost netexec --http-port=8080

$ kubectl get deployments
```
## Step 05: Now you need to allow some security group rules from eks cluster security group to expose your application like below example
```
1. Get inside EKS cluster security group in the networking tab and allow port 80 and 443 to anywhere or via bastionhost

2. Now expose your application using below command:

$ kubectl expose deployment hello-node --type=LoadBalancer --port=8080

$ kubectl get svc

3. To delete the deployment file 

$ kubectl delete service hello-node

$ kubectl delete deployment hello-node

Note: The specific steps may vary depending on your AWS setup and security group configurations. Adjust the rules accordingly based on your network and security requirements.
```
## Step 06: Check whether the logs are shipped to cloudwatch
```
- Goto cloudwatch >> Log-groups >> Fluentd

```
## Step 07: Issues 
```
# IF your eks is not updated with the kubectl file please use the below commands and configure your authentication

$ aws eks update-kubeconfig --region <region name> --name <cluster name>

$ aws eks update-kubeconfig --region us-east-1 --name eksdemo1

-- send terraform-key.pem (your .pem key file) to elasticsearch machine and install kubectl and update the above command 
and start deployment

-- still facing problem check with security groups.

-- check with your aws configure credentials

$ aws sts get-caller-identity

-- check fluentd logs by using below commands

$ kubectl logs -n fluentd <fluentd-pod-name>

$ kubectl logs -n fluentd fluentd-xbh8t
```












